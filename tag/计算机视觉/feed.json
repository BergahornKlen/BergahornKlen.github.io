{
    "version": "https://jsonfeed.org/version/1",
    "title": "Prism Port • All posts by \"计算机视觉\" tag",
    "description": "",
    "home_page_url": "https://www.sycamore.top",
    "items": [
        {
            "id": "https://www.sycamore.top/Homework/%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E7%AF%A1%E6%94%B9%E6%A3%80%E6%B5%8B/",
            "url": "https://www.sycamore.top/Homework/%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E7%AF%A1%E6%94%B9%E6%A3%80%E6%B5%8B/",
            "title": "基于卷积神经网络的图像篡改检测",
            "date_published": "2023-06-19T10:13:25.000Z",
            "content_html": "<div class=\"note info\">\n<p>作业 (o′┏▽┓｀o)</p>\n</div>\n<h2 id=\"图像篡改的类型\"><a class=\"anchor\" href=\"#图像篡改的类型\">#</a> 图像篡改的类型</h2>\n<p>实践中，图像篡改至少有以下几种类型：</p>\n<ol>\n<li>\n<p>图像内容的修改（Tampering），比如通过 PS 实现换脸或者修改合同文字。其中大部分都可以归类到截取、复制、删除。</p>\n</li>\n<li>\n<p>能够间接表达第一类篡改嫌疑的操作（Manipulation）。比如为了遮掩第一类篡改痕迹而做的中值滤波、高斯模糊、高斯噪音以及再次保存图像而产生的二次 JPEG 压缩。</p>\n</li>\n</ol>\n<p>一般而言，图像篡改的最终目的是识别第一类篡改，但是难度很大，需要很深厚的司法、摄影和图像专业知识，比如在传统的图像篡改识别领域，需要使用噪声一致性、几何一致性、光照一致性等方式来进行判断。在实际操作时，需要遍历可疑区域，且每一个可疑区域都需要遍历各种方法进行检验，所以非常地费时费力。</p>\n<p>如果使用机器学习的方法，可以利用图像分割的方式直接将篡改区域分割出来，然而实际训练没有这么简单。</p>\n<p>因为如果使用算法随意地进行图像拼接。这种方式可以生成无限多的数据，但用这些粗糙的训练数据训练出的模型往往无法应对经过精细 PS 的图像，若用同样粗糙的数据做检测，即便获得了好的结果也不能验证模型的有效性。而假如我们一张一张人工 PS，效率太低，完全无法满足训练模型的需要，因此我们的工作主要在识别第二类篡改。</p>\n<p>实验中，我们首先需要通过原始图片生成经过第二类篡改的图片，再生成这些数据对应的标签（已篡改 / 未篡改），然后投入卷积神经网络进行有监督的学习，并在每一轮 epoch 后对当前模型做检测，输出测试的精准度。</p>\n<h2 id=\"卷积神经网络cnn\"><a class=\"anchor\" href=\"#卷积神经网络cnn\">#</a> 卷积神经网络（CNN）</h2>\n<h3 id=\"为什么使用卷积神经网络\"><a class=\"anchor\" href=\"#为什么使用卷积神经网络\">#</a> 为什么使用卷积神经网络</h3>\n<ol>\n<li>\n<p>CNN 和深度神经网络（DNN）</p>\n<p>这里的 DNN 指的是直接用全连接的深度神经网络。</p>\n<p>对于图像而言，如果直接采用全连接的方法，巨大的参数量会造成很多问题，比如巨大的资源消耗、过拟合、局部最优，</p>\n<p>因为图片基本是 1000×1000 像素，再加上 RGB 颜色信息的 3 个参数，就会出现三百万的参数量，这是全连接神经网络绝对无法处理的，所以需要用 CNN 减少参数量级。</p>\n<p>CNN 用卷积层提取图像中的局部特征，用池化层大幅降低参数量级（降维）</p>\n<p>卷积层：</p>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1686727431/Typera/2023/06/4d21c7e3db7073a15d12d724f59dc984.gif\" alt=\"卷积层\" /></p>\n<p>用卷积核来过滤图像的各个小区域，从而得到这些小区域的特征值</p>\n<p>池化层：</p>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1687175841/Typera/2023/06/7e967b5220d5377df9e2c47844537eab.gif\" alt=\"image2\" /></p>\n<p>即使做完了卷积，图像仍然很大（因为卷积核比较小），所以为了降低数据维度，就进行下采样，</p>\n<p>如上图，20×20 的原始图片，采样窗口为 10×10，最终池化结果为一张 2×2 的特征图</p>\n</li>\n<li>\n<p>CNN 和基于特征提取的传统篡改检测</p>\n<p>传统篡改检测方法基于图像统计信息和物理特征检测图像篡改操作，主要针对对复制黏贴和拼接组合两种篡改手段，</p>\n<p>特征提取的方法多种多样，不再赘述，其计算过程大多过于繁琐，运用的函数复杂性远高于 CNN。</p>\n<p>而且对于大数据量的处理，CNN 更有优势：</p>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1686731027/Typera/2023/06/fe4c339cd26fdaa558292c2a0bbe298b.png\" alt=\"CNN\" /></p>\n<h2 id=\"对第二类图像篡改的检测\"><a class=\"anchor\" href=\"#对第二类图像篡改的检测\">#</a> 对第二类图像篡改的检测</h2>\n<h3 id=\"实验数据\"><a class=\"anchor\" href=\"#实验数据\">#</a> 实验数据</h3>\n<p>使用的原始数据集括训练集的 40 张图片和测试集的 20 张图片，均来自以往使用手机拍摄得到（无美颜）。</p>\n<p>首先，我们制作训练数据，用 python 的 cv2 库和 numpy 库实现高斯模糊、高斯噪声、中值模糊、二次 JPEG 压缩、亮度对比度修改等操作，然后篡改原始图片，保存原始图片和篡改后的图片，并保留各自的标签（1/0）。</p>\n<p>训练使用的图像块大小为 28×28，所以训练集截取了约 20 万个图像块，测试集截取了约 10 万个图像块。</p>\n<p>然后定义模型，完成训练后测试数据的准确率。</p>\n<p>我们总共选取了 60 张由手机拍摄的照片，其中 40 张作为训练集，20 张作为测试集。照片的选取需要遵从一定的标准，首先务必保证照片拍摄时没有开启美颜等模式，这会导致模型的训练和测试出现偏差（因为美颜本身也可以视作一种图片篡改）；其次拍摄模糊、歪斜的照片也需要出现在数据集中，这是为了保证数据集的多样性，让我们训练出来的模型面对多样的图片的时候能保持更高的准确性。</p>\n<p>然后我们需要对原始图片进行篡改，生成篡改后的数据集。我们一共实现了高斯模糊、高斯噪声、中值模糊、二次 JPEG 压缩、亮度 / 对比度修改 5 种篡改方法。其中，我们特意加入了亮度 / 对比度修改这种篡改方法，我们认为卷积神经网络在应对这种篡改方面无能为力，但需要经过实验验证。高斯模糊、中值模糊分别通过 cv2 库的 GaussianBlur () 和 medianBlur () 函数实现，其余篡改方法均通过自编写的函数实现。</p>\n<p>最后将篡改后的数据集和原始数据集进行乱序的合并，同时对应的标签（已篡改 / 未篡改）也要一一对应地合并。</p>\n<p>超参数如下：</p>\n<ul>\n<li>网络结构：6 层卷积，简单的 VGG 风格，每 2 层一个 pooling</li>\n<li>优化器：Adam</li>\n<li>epoch 数量：10</li>\n<li>学习率：前 5 个 epoch 学习率 1e-4，后 5 个是 1e-5</li>\n<li>batch_size：一次抓取 50 个样本训练</li>\n</ul>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1687175862/Typera/2023/06/7040e9af89e49b6fddf3e0620c2f7916.png\" alt=\"image44\" /></p>\n<h3 id=\"实验结果\"><a class=\"anchor\" href=\"#实验结果\">#</a> 实验结果</h3>\n<p>高斯模糊、高斯噪声、中值模糊、二次 JPEG 压缩的检测结果都很不错，经过 10 轮 epoch 后，最终的精准度均稳定在 90% 以上。其中高斯噪声达到了 99%，我们认为应该是篡改图本身与原图对比明显的原因，通过对大量篡改图的学习，模型能很轻易地抽象出篡改的特征，从而进行更加精准的判断。</p>\n<p>亮度 / 对比度的精准度只有 50% 左右，这个结果表明，卷积神经网络对图像进行亮度 / 对比度的篡改检测无能为力。我们猜测这也许是因为这种篡改后的图片与原始图片没有本质上的区别，卷积神经网络抽象出的特征是类似于原图的，但这种想法的正确性还有待验证。</p>\n<p>高斯模糊：</p>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1686734917/Typera/2023/06/65359b472aa28e64f839e965bce97108.png\" alt=\"2\" /></p>\n<p>高斯噪声：</p>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1686742374/Typera/2023/06/e9e97cf8a1bd777db7afc55d9db4b480.png\" alt=\"image-20230614193251237\" /></p>\n<p>中值模糊：</p>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1687179264/Typera/2023/06/48ff4fc5e8acecfe8d9a492ca6d8ea11.png\" alt=\"image-20230614205309782\" /></p>\n<p>二次 JPEG 压缩：</p>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1686752710/Typera/2023/06/72c6c4569175987c83df64a5f748b19d.png\" alt=\"image-20230614222506299\" /></p>\n<p>亮度修改：</p>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1686759533/Typera/2023/06/42b9386be2989de4375eb726319b3c13.png\" alt=\"image-20230615001847275\" /></p>\n<p>对比度修改：</p>\n<p><img data-src=\"https://res.cloudinary.com/sycamore/image/upload/v1687179256/Typera/2023/06/5a4fa62d82228b6bc12025547582efe4.png\" alt=\"image-20230615083039860\" /></p>\n</li>\n</ol>\n",
            "tags": [
                "Python",
                "计算机视觉",
                "深度学习"
            ]
        }
    ]
}